{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Single layer Percetrons to Multi-layer neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline\n",
    "* Multi-layer structure\n",
    "* Activation functions\n",
    "* Back-Propagation Algorithm\n",
    "* Stepping through Theano, Lasagne and NoLearn\n",
    "* Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-layer structure\n",
    "![Multi-layer neural network](http://ufldl.stanford.edu/tutorial/images/Network3322.png)\n",
    "Source: http://ufldl.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation functions\n",
    "* Choose an activation function which has a simple derivative\n",
    "\n",
    "## Sigmoid function\n",
    "\n",
    "$$ f(x) = \\frac{1}{1+e^{-x}} $$\n",
    "\n",
    "$$ f'(x) = f(x) (1-f(x)) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.0, 5.0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk8AAAE4CAYAAABCCBeKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAQAA5ALNEwAAQC7QPAEAAOTC/wMDbuyjJOxbgAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10465f990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(-5, 5, 1000)\n",
    "f = 1/(1+np.exp(-(x))) # +0.1 to avoid dividing by 0\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.gca()\n",
    "ax.grid()\n",
    "plt.plot(x, f, color='black')\n",
    "plt.xlim(x.min(), x.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Hyperbolic tangent function\n",
    "\n",
    "$$ f(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}} $$\n",
    "\n",
    "$$ f(x) = 2 * \\frac{1}{1+e^{-2x}} - 1$$\n",
    "\n",
    "$$ f'(x) = 1 - f(x)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.0, 5.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAE4CAYAAACZs72oAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106480650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(-5, 5, 1000)\n",
    "f = 2/(1+np.exp(-(2*x)))-1 # +0.1 to avoid dividing by 0\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.gca()\n",
    "ax.grid()\n",
    "plt.plot(x, f, color='black')\n",
    "plt.xlim(x.min(), x.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* [Great comparison of activation functions](https://en.wikipedia.org/wiki/Activation_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation Algorithm\n",
    "\n",
    "1. Compute forward pass by calculating the activations for $a^{(2)}$ and $a^{(3)}$\n",
    "2. Calculate the cost function $$ J(w) = \\frac{1}{2}(a^{(3)} - y)^2$$\n",
    "3. Calculate the errors $$ \\delta^{(3)} = a^{(3)} - y $$\n",
    "4. Calculate the error for the hidden layer $$ \\delta^{(2)} = (W^{(2)})^T \\delta^{(3)} * \\frac{\\delta \\phi (z^{(2)})}{\\delta z^{(2)}}$$\n",
    "Interestingly, $$ \\frac{\\delta \\phi (z^{(2)})}{\\delta z^{(2)}} = (a^{(2)} \\dot (1-a^{(2)}))$$ \n",
    "\n",
    "5. Calculate the change of the weights\n",
    "$$ \\Delta^{(l)}_{i,j} = \\Delta^{(l)}_{i,j} + a^{(l)}_{j} \\delta^{(l+1)}_{i}$$\n",
    "6. Update the weights\n",
    "$$ W^{(l)} = W^{(l)} - \\eta \\Delta^{(l)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools to calculate neural networks\n",
    "\n",
    " * Theano: Symbolic computation library for Python (Cuda support)\n",
    " * Lasagne: Neural network library based on Theano\n",
    " * NoLearn: Python wrapper for Lasagne\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NoLearn\n",
    "In NoLearn, you can define the network layers as a Python list\n",
    "\n",
    "```\n",
    "layers = [\n",
    "    (InputLayer, {'shape': (1, X.shape[1],)}),\n",
    "    (DenseLayer, {'num_units': 2, 'nonlinearity': sigmoid}),\n",
    "    (DenseLayer, {'num_units': 2, 'nonlinearity': softmax}),\n",
    "]\n",
    "```\n",
    "\n",
    "and pass it to the neural network definition\n",
    "```\n",
    "net1 = NeuralNet(\n",
    "    layers=layers,\n",
    "    max_epochs=100,\n",
    "    update_learning_rate=1,\n",
    "    train_split=TrainSplit(eval_size=0),\n",
    "    verbose=3,\n",
    ")\n",
    "```\n",
    "\n",
    "Use `net.fit(X, y)` and `net.predict(X)` to train and for your prediction, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Things to do:\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR prediction with a Multi-layer neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 12 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name      size\n",
      "---  ------  ------\n",
      "  0  input0       2\n",
      "  1  dense1       2\n",
      "  2  dense2       2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m0.86845\u001b[0m           nan          nan          nan  0.00s\n",
      "      2       \u001b[36m0.70835\u001b[0m           nan          nan          nan  0.00s\n",
      "      3       0.72555           nan          nan          nan  0.00s\n",
      "      4       \u001b[36m0.69603\u001b[0m           nan          nan          nan  0.00s\n",
      "      5       \u001b[36m0.68923\u001b[0m           nan          nan          nan  0.00s\n",
      "      6       0.68932           nan          nan          nan  0.00s\n",
      "      7       \u001b[36m0.68814\u001b[0m           nan          nan          nan  0.00s\n",
      "      8       \u001b[36m0.68718\u001b[0m           nan          nan          nan  0.00s\n",
      "      9       \u001b[36m0.68629\u001b[0m           nan          nan          nan  0.00s\n",
      "     10       \u001b[36m0.68522\u001b[0m           nan          nan          nan  0.00s\n",
      "     11       \u001b[36m0.68393\u001b[0m           nan          nan          nan  0.00s\n",
      "     12       \u001b[36m0.68238\u001b[0m           nan          nan          nan  0.00s\n",
      "     13       \u001b[36m0.68050\u001b[0m           nan          nan          nan  0.00s\n",
      "     14       \u001b[36m0.67820\u001b[0m           nan          nan          nan  0.00s\n",
      "     15       \u001b[36m0.67541\u001b[0m           nan          nan          nan  0.00s\n",
      "     16       \u001b[36m0.67202\u001b[0m           nan          nan          nan  0.00s\n",
      "     17       \u001b[36m0.66790\u001b[0m           nan          nan          nan  0.00s\n",
      "     18       \u001b[36m0.66293\u001b[0m           nan          nan          nan  0.00s\n",
      "     19       \u001b[36m0.65695\u001b[0m           nan          nan          nan  0.00s\n",
      "     20       \u001b[36m0.64980\u001b[0m           nan          nan          nan  0.00s\n",
      "     21       \u001b[36m0.64132\u001b[0m           nan          nan          nan  0.00s\n",
      "     22       \u001b[36m0.63133\u001b[0m           nan          nan          nan  0.00s\n",
      "     23       \u001b[36m0.61965\u001b[0m           nan          nan          nan  0.00s\n",
      "     24       \u001b[36m0.60608\u001b[0m           nan          nan          nan  0.00s\n",
      "     25       \u001b[36m0.59043\u001b[0m           nan          nan          nan  0.00s\n",
      "     26       \u001b[36m0.57243\u001b[0m           nan          nan          nan  0.00s\n",
      "     27       \u001b[36m0.55180\u001b[0m           nan          nan          nan  0.00s\n",
      "     28       \u001b[36m0.52819\u001b[0m           nan          nan          nan  0.00s\n",
      "     29       \u001b[36m0.50121\u001b[0m           nan          nan          nan  0.00s\n",
      "     30       \u001b[36m0.47049\u001b[0m           nan          nan          nan  0.00s\n",
      "     31       \u001b[36m0.43581\u001b[0m           nan          nan          nan  0.00s\n",
      "     32       \u001b[36m0.39730\u001b[0m           nan          nan          nan  0.00s\n",
      "     33       \u001b[36m0.35560\u001b[0m           nan          nan          nan  0.00s\n",
      "     34       \u001b[36m0.31197\u001b[0m           nan          nan          nan  0.00s\n",
      "     35       \u001b[36m0.26820\u001b[0m           nan          nan          nan  0.00s\n",
      "     36       \u001b[36m0.22627\u001b[0m           nan          nan          nan  0.00s\n",
      "     37       \u001b[36m0.18792\u001b[0m           nan          nan          nan  0.00s\n",
      "     38       \u001b[36m0.15432\u001b[0m           nan          nan          nan  0.00s\n",
      "     39       \u001b[36m0.12592\u001b[0m           nan          nan          nan  0.00s\n",
      "     40       \u001b[36m0.10257\u001b[0m           nan          nan          nan  0.00s\n",
      "     41       \u001b[36m0.08375\u001b[0m           nan          nan          nan  0.00s\n",
      "     42       \u001b[36m0.06877\u001b[0m           nan          nan          nan  0.00s\n",
      "     43       \u001b[36m0.05691\u001b[0m           nan          nan          nan  0.00s\n",
      "     44       \u001b[36m0.04755\u001b[0m           nan          nan          nan  0.00s\n",
      "     45       \u001b[36m0.04012\u001b[0m           nan          nan          nan  0.00s\n",
      "     46       \u001b[36m0.03422\u001b[0m           nan          nan          nan  0.00s\n",
      "     47       \u001b[36m0.02949\u001b[0m           nan          nan          nan  0.00s\n",
      "     48       \u001b[36m0.02568\u001b[0m           nan          nan          nan  0.00s\n",
      "     49       \u001b[36m0.02257\u001b[0m           nan          nan          nan  0.00s\n",
      "     50       \u001b[36m0.02003\u001b[0m           nan          nan          nan  0.00s\n",
      "     51       \u001b[36m0.01793\u001b[0m           nan          nan          nan  0.00s\n",
      "     52       \u001b[36m0.01618\u001b[0m           nan          nan          nan  0.00s\n",
      "     53       \u001b[36m0.01472\u001b[0m           nan          nan          nan  0.00s\n",
      "     54       \u001b[36m0.01348\u001b[0m           nan          nan          nan  0.00s\n",
      "     55       \u001b[36m0.01242\u001b[0m           nan          nan          nan  0.00s\n",
      "     56       \u001b[36m0.01152\u001b[0m           nan          nan          nan  0.00s\n",
      "     57       \u001b[36m0.01074\u001b[0m           nan          nan          nan  0.00s\n",
      "     58       \u001b[36m0.01006\u001b[0m           nan          nan          nan  0.00s\n",
      "     59       \u001b[36m0.00947\u001b[0m           nan          nan          nan  0.00s\n",
      "     60       \u001b[36m0.00895\u001b[0m           nan          nan          nan  0.00s\n",
      "     61       \u001b[36m0.00850\u001b[0m           nan          nan          nan  0.00s\n",
      "     62       \u001b[36m0.00810\u001b[0m           nan          nan          nan  0.00s\n",
      "     63       \u001b[36m0.00774\u001b[0m           nan          nan          nan  0.00s\n",
      "     64       \u001b[36m0.00742\u001b[0m           nan          nan          nan  0.00s\n",
      "     65       \u001b[36m0.00713\u001b[0m           nan          nan          nan  0.00s\n",
      "     66       \u001b[36m0.00687\u001b[0m           nan          nan          nan  0.00s\n",
      "     67       \u001b[36m0.00664\u001b[0m           nan          nan          nan  0.00s\n",
      "     68       \u001b[36m0.00643\u001b[0m           nan          nan          nan  0.00s\n",
      "     69       \u001b[36m0.00623\u001b[0m           nan          nan          nan  0.00s\n",
      "     70       \u001b[36m0.00606\u001b[0m           nan          nan          nan  0.00s\n",
      "     71       \u001b[36m0.00589\u001b[0m           nan          nan          nan  0.00s\n",
      "     72       \u001b[36m0.00575\u001b[0m           nan          nan          nan  0.00s\n",
      "     73       \u001b[36m0.00561\u001b[0m           nan          nan          nan  0.00s\n",
      "     74       \u001b[36m0.00548\u001b[0m           nan          nan          nan  0.00s\n",
      "     75       \u001b[36m0.00537\u001b[0m           nan          nan          nan  0.00s\n",
      "     76       \u001b[36m0.00526\u001b[0m           nan          nan          nan  0.00s\n",
      "     77       \u001b[36m0.00515\u001b[0m           nan          nan          nan  0.00s\n",
      "     78       \u001b[36m0.00506\u001b[0m           nan          nan          nan  0.00s\n",
      "     79       \u001b[36m0.00497\u001b[0m           nan          nan          nan  0.00s\n",
      "     80       \u001b[36m0.00489\u001b[0m           nan          nan          nan  0.00s\n",
      "     81       \u001b[36m0.00481\u001b[0m           nan          nan          nan  0.00s\n",
      "     82       \u001b[36m0.00473\u001b[0m           nan          nan          nan  0.00s\n",
      "     83       \u001b[36m0.00466\u001b[0m           nan          nan          nan  0.00s\n",
      "     84       \u001b[36m0.00460\u001b[0m           nan          nan          nan  0.00s\n",
      "     85       \u001b[36m0.00453\u001b[0m           nan          nan          nan  0.00s\n",
      "     86       \u001b[36m0.00447\u001b[0m           nan          nan          nan  0.00s\n",
      "     87       \u001b[36m0.00441\u001b[0m           nan          nan          nan  0.00s\n",
      "     88       \u001b[36m0.00436\u001b[0m           nan          nan          nan  0.00s\n",
      "     89       \u001b[36m0.00430\u001b[0m           nan          nan          nan  0.00s\n",
      "     90       \u001b[36m0.00425\u001b[0m           nan          nan          nan  0.00s\n",
      "     91       \u001b[36m0.00420\u001b[0m           nan          nan          nan  0.00s\n",
      "     92       \u001b[36m0.00416\u001b[0m           nan          nan          nan  0.00s\n",
      "     93       \u001b[36m0.00411\u001b[0m           nan          nan          nan  0.00s\n",
      "     94       \u001b[36m0.00407\u001b[0m           nan          nan          nan  0.00s\n",
      "     95       \u001b[36m0.00403\u001b[0m           nan          nan          nan  0.00s\n",
      "     96       \u001b[36m0.00399\u001b[0m           nan          nan          nan  0.00s\n",
      "     97       \u001b[36m0.00395\u001b[0m           nan          nan          nan  0.00s\n",
      "     98       \u001b[36m0.00391\u001b[0m           nan          nan          nan  0.00s\n",
      "     99       \u001b[36m0.00387\u001b[0m           nan          nan          nan  0.00s\n",
      "    100       \u001b[36m0.00383\u001b[0m           nan          nan          nan  0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNet(X_tensor_type=None,\n",
       "     batch_iterator_test=<nolearn.lasagne.base.BatchIterator object at 0x107ac1590>,\n",
       "     batch_iterator_train=<nolearn.lasagne.base.BatchIterator object at 0x107ac1450>,\n",
       "     custom_scores=None,\n",
       "     layers=[(<class 'lasagne.layers.input.InputLayer'>, {'shape': (1, 2)}), (<class 'lasagne.layers.dense.DenseLayer'>, {'num_units': 2, 'nonlinearity': <function sigmoid at 0x107af6aa0>}), (<class 'lasagne.layers.dense.DenseLayer'>, {'num_units': 2, 'nonlinearity': <function softmax at 0x107af6de8>})],\n",
       "     loss=None, max_epochs=100, more_params={},\n",
       "     objective=<function objective at 0x1060049b0>,\n",
       "     objective_loss_function=<function categorical_crossentropy at 0x105f53050>,\n",
       "     on_batch_finished=[],\n",
       "     on_epoch_finished=[<nolearn.lasagne.handlers.PrintLog instance at 0x1084357e8>],\n",
       "     on_training_finished=[],\n",
       "     on_training_started=[<nolearn.lasagne.handlers.PrintLayerInfo instance at 0x108435ea8>],\n",
       "     regression=False,\n",
       "     train_split=<nolearn.lasagne.base.TrainSplit object at 0x108445110>,\n",
       "     update=<function nesterov_momentum at 0x105f53938>,\n",
       "     update_learning_rate=1, use_label_encoder=False, verbose=3,\n",
       "     y_tensor_type=TensorType(int32, vector))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from lasagne.layers import DenseLayer\n",
    "from lasagne.layers import InputLayer\n",
    "from lasagne.nonlinearities import softmax, sigmoid\n",
    "\n",
    "from nolearn.lasagne import TrainSplit\n",
    "from nolearn.lasagne import NeuralNet\n",
    "\n",
    "data_set = np.array([\n",
    "    [0, 0, 0],\n",
    "    [0, 1, 1],\n",
    "    [1, 0, 1],\n",
    "    [1, 1, 0],\n",
    "])\n",
    "\n",
    "X = data_set[:, :2]\n",
    "y = data_set[:, 2:]\n",
    "X = np.array(X).astype(np.float32)\n",
    "y = np.array(y).ravel().astype(np.int32)\n",
    "\n",
    "layers = [\n",
    "    (InputLayer, {'shape': (1, X.shape[1],)}),\n",
    "    (DenseLayer, {'num_units': 2, 'nonlinearity': sigmoid}),\n",
    "    (DenseLayer, {'num_units': 2, 'nonlinearity': softmax}),\n",
    "]\n",
    "\n",
    "net1 = NeuralNet(\n",
    "    layers=layers,\n",
    "    max_epochs=100,\n",
    "    update_learning_rate=1,\n",
    "    train_split=TrainSplit(eval_size=0),\n",
    "    verbose=3,  \n",
    ")\n",
    "net1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the model by predicting the output for (1, 1)\n",
    "net1.predict([[1, 1],])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit card approval prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "nesterov_momentum() takes at least 3 arguments (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-23a443c431c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m     )\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mcredit_approval_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/birajbisht/anaconda/lib/python2.7/site-packages/nolearn/lasagne/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, epochs)\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/birajbisht/anaconda/lib/python2.7/site-packages/nolearn/lasagne/base.pyc\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    357\u001b[0m         iter_funcs = self._create_iter_funcs(\n\u001b[1;32m    358\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_tensor_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m             )\n\u001b[1;32m    361\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_iter_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_iter_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter_funcs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/birajbisht/anaconda/lib/python2.7/site-packages/nolearn/lasagne/base.pyc\u001b[0m in \u001b[0;36m_create_iter_funcs\u001b[0;34m(self, layers, objective, update, output_type)\u001b[0m\n\u001b[1;32m    481\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mgrad_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0mupdate_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_params_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'update'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m         \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mupdate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         input_layers = [layer for layer in layers.values()\n",
      "\u001b[0;31mTypeError\u001b[0m: nesterov_momentum() takes at least 3 arguments (2 given)"
     ]
    }
   ],
   "source": [
    "# data from https://onlinecourses.science.psu.edu/stat857/node/215\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lasagne.layers import DenseLayer\n",
    "from lasagne.layers import InputLayer\n",
    "from lasagne.nonlinearities import softmax, tanh\n",
    "\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from nolearn.lasagne import TrainSplit\n",
    "\n",
    "training_set = pd.read_csv('../../data/German_credit_card_training_500.csv')\n",
    "training_set = training_set.sort_values(\n",
    "    ['Creditability',]).head(\n",
    "    2 * len(training_set[(training_set['Creditability'] == 0)])\n",
    ")\n",
    "# test_set = pd.read_csv('german_credit_dataset/Test50.csv')\n",
    "# extract the creditability column as y vector\n",
    "y = training_set['Creditability'].values\n",
    "# drop the creditability column from the dataset\n",
    "training_set.drop('Creditability', axis=1, inplace=True)\n",
    "\n",
    "# remaining dataset is used as input matrix\n",
    "X = np.array(training_set.values).astype(np.float32)\n",
    "y = np.array(y).astype(np.int32)\n",
    "\n",
    "# apply some very simple normalization to the data\n",
    "X -= X.mean()\n",
    "X /= X.std()\n",
    "\n",
    "credit_approval_net = NeuralNet(\n",
    "    layers=[  # three layers: one hidden layer\n",
    "        (InputLayer, {'shape': (None, X.shape[1],)}),\n",
    "        (DenseLayer, {'num_units': 2, 'nonlinearity': sigmoid}),\n",
    "        (DenseLayer, {'num_units': 2, 'nonlinearity': softmax}),\n",
    "        ],\n",
    "    # setup the training parameters\n",
    "    )\n",
    "\n",
    "credit_approval_net.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# determine score on test set\n",
    "training_set = pd.read_csv('../../data/German_credit_card_test_500.csv')\n",
    "training_set = training_set.sort_values(\n",
    "    ['Creditability',]).head(\n",
    "    2 * len(training_set[(training_set['Creditability'] == 0)])\n",
    ")\n",
    "# test_set = pd.read_csv('german_credit_dataset/Test50.csv')\n",
    "# extract the creditability column as y vector\n",
    "y_test = training_set['Creditability'].values\n",
    "# drop the creditability column from the dataset\n",
    "training_set.drop('Creditability', axis=1, inplace=True)\n",
    "\n",
    "# remaining dataset is used as input matrix\n",
    "X_test = np.array(training_set.values).astype(np.float32)\n",
    "y_test = np.array(y_test).astype(np.int32)\n",
    "\n",
    "# apply some very simple normalization to the data\n",
    "X_test -= X_test.mean()\n",
    "X_test /= X_test.std()\n",
    "\n",
    "# run test set with test data\n",
    "credit_approval_net.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify hand-written numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle, gzip, numpy\n",
    "\n",
    "# Load the dataset\n",
    "f = gzip.open('../../data/mnist.pkl.gz', 'rb')\n",
    "training_set, valid_set, test_set = cPickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = training_set[0]\n",
    "y_train = training_set[1]\n",
    "X_test = test_set[0]\n",
    "y_test = test_set[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Python is not installed as a framework. The Mac OS X backend will not be able to function correctly if Python is not installed as a framework. See the Python documentation for more information on installing Python as a framework on Mac OS X. Please either reinstall Python as a framework, or try one of the other backends. If you are Working with Matplotlib in a virtual enviroment see 'Working with Matplotlib in Virtual environments' in the Matplotlib FAQ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-fd853199cdd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'pylab inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/birajbisht/anaconda/lib/python2.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpylab_setup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m \u001b[0m_backend_mod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_figure_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdraw_if_interactive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_show\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpylab_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0m_IP_REGISTERED\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/birajbisht/anaconda/lib/python2.7/site-packages/matplotlib/backends/__init__.pyc\u001b[0m in \u001b[0;36mpylab_setup\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# imports. 0 means only perform absolute imports.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     backend_mod = __import__(backend_name,\n\u001b[0;32m---> 32\u001b[0;31m                              globals(),locals(),[backend_name],0)\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Things we pull in from all backends\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/birajbisht/anaconda/lib/python2.7/site-packages/matplotlib/backends/backend_macosx.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_macosx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Python is not installed as a framework. The Mac OS X backend will not be able to function correctly if Python is not installed as a framework. See the Python documentation for more information on installing Python as a framework on Mac OS X. Please either reinstall Python as a framework, or try one of the other backends. If you are Working with Matplotlib in a virtual enviroment see 'Working with Matplotlib in Virtual environments' in the Matplotlib FAQ"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "%pylab inline\n",
    "\n",
    "def get_images(training_set):\n",
    "    \"\"\" Return a list containing the images from the MNIST data\n",
    "    set. Each image is represented as a 2-d numpy array.\n",
    "    \n",
    "    source: https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/fig/mnist.py\n",
    "    \"\"\"\n",
    "    flattened_images = training_set[0]\n",
    "    return [np.reshape(f, (-1, 28)) for f in flattened_images]\n",
    "\n",
    "def plot_10_by_10_images(images):\n",
    "    \"\"\" Plot 100 MNIST images in a 10 by 10 table. \"\"\"\n",
    "    figs, axes = plt.subplots(4, 4, figsize=(6, 6))\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            axes[i, j].imshow(-X_train[i + 4 * j].reshape(28, 28), cmap='gray', interpolation='none')\n",
    "            axes[i, j].set_xticks([])\n",
    "            axes[i, j].set_yticks([])\n",
    "            axes[i, j].set_title(\"Label: {}\".format(y[i + 4 * j]))\n",
    "            axes[i, j].axis('off')\n",
    "    \n",
    "images = get_images(training_set)\n",
    "plot_10_by_10_images(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lasagne.layers import DenseLayer\n",
    "from lasagne.layers import InputLayer\n",
    "from lasagne.nonlinearities import softmax, tanh\n",
    "\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from nolearn.lasagne import TrainSplit\n",
    "\n",
    "X = X_train.astype(np.float32)\n",
    "y = y_train.astype(np.int32)\n",
    "\n",
    "# apply some very simple normalization to the data\n",
    "X -= X.mean()\n",
    "X /= X.std()\n",
    "\n",
    "mnist_net = NeuralNet(\n",
    "    layers=[  # three layers: one hidden layer\n",
    "        (InputLayer, {'shape': (None, X.shape[1], )}),\n",
    "        (DenseLayer, {'num_units': 50, 'nonlinearity': sigmoid}),\n",
    "        (DenseLayer, {'num_units': 10, 'nonlinearity': softmax}),\n",
    "        ],\n",
    "    update_learning_rate=0.1,\n",
    "    max_epochs=5,  # we want to train this many epochs\n",
    "    verbose=2,\n",
    "    train_split=TrainSplit(eval_size=0.25),\n",
    "    )\n",
    "\n",
    "mnist_net.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist_net.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Effective Backpropagation, pdf](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf)\n",
    "* [Comparison of activation functions](https://en.wikipedia.org/wiki/Activation_function)\n",
    "* [Introduction to Theano](http://on-demand.gputechconf.com/gtc/2015/webinar/deep-learning-course/getting-started-with-theano.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
